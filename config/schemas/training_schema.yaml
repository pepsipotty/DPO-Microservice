# Training Configuration Schema
# Validates the main training configuration structure

type: object
properties:
  seed:
    type: integer
    minimum: 0
    description: "Random seed for batch sampling"
  
  exp_name:
    type: string
    description: "Experiment name for local run directory and wandb"
  
  batch_size:
    type: integer
    minimum: 1
    description: "Batch size for training"
  
  eval_batch_size:
    type: integer
    minimum: 1
    description: "Batch size during evaluation and sampling"
  
  debug:
    type: boolean
    description: "Debug mode (disables wandb, model checkpointing, etc.)"
  
  fsdp_port:
    type: ["integer", "null"]
    description: "Port to use for FSDP"
  
  datasets:
    type: array
    items:
      type: string
    minItems: 1
    description: "Dataset(s) to train on"
  
  wandb:
    type: object
    properties:
      enabled:
        type: boolean
      entity:
        type: ["string", "null"]
      project:
        type: string
    required: ["enabled", "project"]
    description: "Wandb configuration"
  
  local_dirs:
    type: array
    items:
      type: string
    minItems: 1
    description: "Local directories for run directory and cache"
  
  sample_during_eval:
    type: boolean
    description: "Whether to generate samples during evaluation"
  
  n_eval_model_samples:
    type: integer
    minimum: 1
    description: "Number of model samples to generate during evaluation"
  
  do_first_eval:
    type: boolean
    description: "Whether to eval at the very beginning of training"
  
  local_run_dir:
    type: string
    description: "Local run directory path"
  
  lr:
    type: number
    minimum: 0
    description: "Learning rate"
  
  gradient_accumulation_steps:
    type: integer
    minimum: 1
    description: "Number of steps to accumulate over for each batch"
  
  per_device_train_batch_size:
    type: integer
    minimum: 1
    description: "Per device training batch size"
  
  max_grad_norm:
    type: number
    minimum: 0
    description: "Maximum gradient norm to clip to"
  
  max_length:
    type: integer
    minimum: 1
    description: "Maximum allowed length for an input (prompt + response)"
  
  max_prompt_length:
    type: integer
    minimum: 1
    description: "Maximum allowed length for a prompt"
  
  n_epochs:
    type: ["integer", "null"]
    minimum: 1
    description: "Number of epochs to train for"
  
  n_examples:
    type: ["integer", "null"]
    minimum: 1
    description: "Number of examples to train for"
  
  n_eval_examples:
    type: integer
    minimum: 1
    description: "Number of examples to evaluate on"
  
  trainer:
    type: string
    enum: ["BasicTrainer", "FSDPTrainer", "TensorParallelTrainer"]
    description: "Trainer class to use"
  
  optimizer:
    type: string
    enum: ["Adam", "AdamW", "RMSprop", "SGD"]
    description: "Optimizer to use"
  
  warmup_steps:
    type: integer
    minimum: 0
    description: "Number of linear warmup steps for learning rate"
  
  activation_checkpointing:
    type: boolean
    description: "Whether to use activation/gradient checkpointing"
  
  eval_every:
    type: integer
    minimum: 1
    description: "Evaluate and save model every eval_every steps"
  
  minimum_log_interval_secs:
    type: number
    minimum: 0
    description: "Minimum log interval for wandb"
  
  defaults:
    type: array
    items:
      oneOf:
        - type: string
        - type: object
    description: "Hydra defaults list"
  
  loss:
    type: object
    properties:
      beta:
        type: number
        minimum: 0
        description: "Beta parameter for DPO loss"
    description: "Loss configuration override"

required:
  - seed
  - exp_name
  - batch_size
  - eval_batch_size
  - debug
  - datasets
  - wandb
  - local_dirs
  - sample_during_eval
  - n_eval_model_samples
  - do_first_eval
  - local_run_dir
  - lr
  - gradient_accumulation_steps
  - per_device_train_batch_size
  - max_grad_norm
  - max_length
  - max_prompt_length
  - n_eval_examples
  - trainer
  - optimizer
  - warmup_steps
  - activation_checkpointing
  - eval_every
  - minimum_log_interval_secs
  - defaults

additionalProperties: true